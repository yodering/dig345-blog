---
title: 'DevLog 5-3'
description: 'Create an interactive sound experience'
pubDate: '2026-02-23'
---

Review the Sound & Music page to learn Tone.js and Strudel.
Complete the Strudel First Sounds tutorial. Post a link to your finished REPL ✏️ here.
<iframe 
  src="https://strudel.cc/#CnNvdW5kKCJiZCo0LCBbLSBjcF0qMiwgWy0gaGhdKjQiKS5iYW5rKCJSb2xhbmRUUjkwOSIp" 
  width="100%" 
  height="400" 
  frameborder="0"
/>
Complete the Strudel First Notes tutorial. Post a link to your finished REPL
<iframe 
  src="https://strudel.cc/#Cm4oYDwKW34gMF0gMiBbMCAyXSBbfiAyXQpbfiAwXSAxIFswIDFdIFt%2BIDFdClt%2BIDBdIDMgWzAgM10gW34gM10KW34gMF0gMiBbMCAyXSBbfiAyXQo%2BKjRgKS5zY2FsZSgiQzQ6bWFqb3IiKQouc291bmQoImdtX3N5bnRoX3N0cmluZ3NfMSIp" 
  width="100%" 
  height="400" 
  frameborder="0"
/>
Complete the Strudel First Effects tutorial. Post a link to your finished REPL 
<iframe 
  src="https://strudel.cc/#Cm4oYDwKW34gMF0gMiBbMCAyXSBbfiAyXQpbfiAwXSAxIFswIDFdIFt%2BIDFdClt%2BIDBdIDMgWzAgM10gW34gM10KW34gMF0gMiBbMCAyXSBbfiAyXQo%2BKjRgKS5zY2FsZSgiQzQ6bWFqb3IiKQouc291bmQoImdtX3N5bnRoX3N0cmluZ3NfMSIpLmdhaW4oc2luZSk%3D" 
  width="100%" 
  height="400" 
  frameborder="0"
/>

Music Mouse Explained | Laurie Spiegel on Algorithmic Composition (1987 Archive) (27:38). Post a reading response in your DevLog per information in the Assignments.
Complete all five parts of the Getting Started with Tone.js | Web Audio Tutorial - Pts 1-5 (3:31, 6:37, 10:20, 5:59, 9:28). Post a link to your finished project online ✏️ here: https://github.com/yodering/tone

Explore the inspiring examples below.
Design and code an “interactive audio experience” that makes use of Tone.js. Consider using shapes, color, and other visuals in addition to sounds. This need not be fancy or polished, since you have less than a week to complete it. Try to have fun creating.
Post designs mockups (pencil/paper, Figma, etc.) here. Used my previous Patatap clone to take inspiration.

Post links to your project, a video, and a 100-150 word statement about the concept and technology of your interactive audio experience ✏️ here.
https://yodering.github.io/devlog5-3/

This project is a remake of my earlier Patatap-style interactive audio experience. Each key on the keyboard triggers a unique sound paired with a simple visual animation, encouraging playful exploration. Instead of listening to a fixed track, users create their own compositions in real time by layering sounds through interaction. The experience was built using JavaScript with the Web Audio API and Tone.js for sound generation and control, along with canvas-based animations for visual feedback. The goal was to create a responsive, browser-based instrument that feels immediate and intuitive while demonstrating how interactive audio can turn simple inputs into expressive digital performances.


Optional Challenge: Use the Strudel device motion and input devices to create your audio experience.

Summary
In this 1987 episode of Midnight Muse, composer and programmer Laurie Spiegel demonstrates Music Mouse, her algorithmic composition software originally released in 1986 for Mac, Amiga, and Atari computers. The program uses an XY grid controlled by the mouse to generate harmonically coherent melodies and chord voicings across four simultaneous voices. Rather than a sequencer or notation tool, Spiegel frames it as an "intelligent instrument" — one that automates lower-level musical decisions (like voice-leading and scale adherence) so that the player can focus on expressive gesture and real-time musical movement. Spiegel takes live call-in questions from viewers, discussing how the software supports creativity rather than replacing it, and why she sees the computer as a kind of modern folk instrument that democratizes music-making for people without formal training.

Quote
"Even if we're very good at the keyboard, sometimes we want our habits broken up."
— Laurie Spiegel

Comment
What strikes me most is how precisely Spiegel distinguishes augmentation from automation — a distinction that still trips people up today when discussing AI-generated art. Music Mouse doesn't compose for you; it constrains the possibility space so that whatever you do falls within musical logic. The intelligence is baked into the rules of the system, not in the output. That's a fundamentally different relationship between human and machine than what most people imagine when they hear "algorithmic composition," and it's remarkable that she was articulating this so clearly in 1987.

Comment
What strikes me most is how precisely Spiegel distinguishes augmentation from automation; a distinction that still trips people up today when discussing AI-generated art. Music Mouse doesn't compose for you; it constrains the possibility space so that whatever you do falls within musical logic. The intelligence is baked into the rules of the system, not in the output.

Discussion Question
Spiegel argues that by automating "lower-level" decisions (harmony, voice-leading, scale selection), the performer is freed to focus on higher-level expression — but who decides which decisions are "lower" and which are "higher"? Is that hierarchy neutral, or does it encode a particular aesthetic ideology about what music is supposed to feel like?

Related Work
Brian Eno and Peter Schmid's Oblique Strategies (1975) - a deck of cards offering aphoristic instructions to break creative habits - operates on a similar philosophical premise as Music Mouse. Both treat the creative block or muscle memory not as something to power through, but as something a system can gently disrupt.
